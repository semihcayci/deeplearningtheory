<!doctype html>
<html>
<head>
    <title>8_References</title>
    <meta charset="utf-8">
    
</head>
<body>
<h2>References</h2><h3><p dir="ltr" style="text-align: left;">References on the analysis of neural networks near initialization.</p></h3><p dir="ltr" style="text-align: left;">A good resource on the neural tangent kernel analysis is Matus Telgarsky's Deep Learning Theory lecture notes (Chapter 4):&nbsp;<a href="https://mjt.cs.illinois.edu/dlt/index.pdf">https://mjt.cs.illinois.edu/dlt/index.pdf</a></p><p dir="ltr" style="text-align: left;"><br></p><p dir="ltr" style="text-align: left;">NTK analysis was established in the following papers:</p><p dir="ltr" style="text-align: left;"></p><ul><li>Du, Simon S., et al. "Gradient descent provably optimizes over-parameterized neural networks."&nbsp;<i>arXiv preprint arXiv:1810.02054</i>&nbsp;(2018).<br></li><li>Jacot, Arthur, Franck Gabriel, and Cl√©ment Hongler. "Neural tangent kernel: Convergence and generalization in neural networks."&nbsp;<i>Advances in neural information processing systems</i>31 (2018).<br></li><li>Chizat, Lenaic, Edouard Oyallon, and Francis Bach. "On lazy training in differentiable programming."&nbsp;<i>Advances in neural information processing systems</i>&nbsp;32 (2019).<br></li></ul><p></p>
</body>
</html>